---
title: "Working Rmd"
author: '100385774'
date: "2023-04-18"
output: html_document
---

# 0. Loading the data

Data has been previously compiled into a single .csv document in the 'Preliminar.Rmd' file. 

```{r}
library(tidyverse)
library(data.table)
library(ggplot2)
library(stringr)
library(openxlsx)
library(lubridate)
library(emo)
library(stopwords)
```


```{r}
df <- fread("data/tweets.csv")
```

# 1. Manual annotation

Duplicates removal, Spanish filtering: 

```{r}
df <- df %>% 
  distinct() %>% 
  filter(lang == "es") 
```

## Manual annotations

Filtering search for hate terms + random sampling.   

```{r}
set.seed(123)

annotation_1 <- df %>% 
  filter(str_detect(df$text, "moro")) %>% 
   sample_n(500, replace = FALSE)

annotation_2 <- df %>% 
  filter(str_detect(df$text, "negro|mono")) %>% 
   sample_n(500, replace = FALSE)

annotation_3 <- df %>% 
  filter(str_detect(df$text, "chino|sudaca|panchito|gitano")) %>% 
   sample_n(500, replace = FALSE)

annotation_4 <- df %>% 
  filter(str_detect(df$text, "maricon|maricÃ³n|travelo|transexual|travesti")) %>% 
   sample_n(500, replace = FALSE)

annotation_5 <- df %>% 
  filter(str_detect(df$text, "a tu pais|a tu paÃ­s|a su pais|a su paÃ­s")) %>% 
   sample_n(500, replace = FALSE)

annotation_6 <- df %>% 
  filter(str_detect(df$text, "puta|zorra|a la cocina|chupapollas")) %>% 
   sample_n(500, replace = FALSE)

annotation_random <- df %>% 
             sample_n(2000, replace = FALSE)
```

```{r}

annotation <- bind_rows(annotation_1, annotation_2, annotation_3, annotation_4, annotation_5, annotation_6, annotation_random) %>% 
  distinct() %>% 
  mutate(hate = 0) %>% 
  select(c(text, hate, id))

write.xlsx(annotation, file = "annotationbis.xlsx")

```

# 2. Data Preprocessing and NLP Techniques: 

*APPLY LATER CLD3 PACKAGE

Noise removal (bots), Boolean mention and URL presence, lower casing, time conversion: 

```{r}
df <- df %>% 
  select(-c(lang, entities.hashtags)) %>% 
  distinct(text, author_id, .keep_all = TRUE) %>% 
  mutate(entities.mentions = ifelse(entities.mentions == "", F, T),
         entities.urls = ifelse(entities.urls == "", F, T),
         text = str_remove_all(text, "@.{1,15} "),
         text = str_remove_all(text, "https://.*\\b"),
         text = tolower(text), 
         created_at = as.POSIXct(created_at))
```

Emojis tokenization: 

```{r}
df <- df %>% 
  mutate(text = str_replace_all(text, "ğŸ»|ğŸ¼|ğŸ½|ğŸ¾|ğŸ¿", ""),
         text = str_replace_all(text, "\\\\n|&lt", " "), 
         text = str_replace_all(text, "ğŸ¤£+|ğŸ˜‚+", ":risa:"),
         text = str_replace_all(text, "ğŸ€+", ":rata:"),
         text = str_replace_all(text, "ğŸ˜¡+|ğŸ”ª+|ğŸ¤¬+|ğŸ‘Š+|ğŸª“+|ğŸ¤®+|ğŸ’©+", ":enfado:"),
         text = str_replace_all(text, "ğŸ‘+|ğŸ’ª+|âœŠ+|ğŸ’ª+|â¤ï¸+|ğŸ¥°+|â¤+|ğŸ¤+", ":positividad:"),
         text = ji_replace_all(text, ""),
         text = iconv(text, to = "UTF-8//IGNORE"),
         text = str_replace_all(text, "jajaja.*\\.?\\s?|jsjsjs.*\\.?\\s?|jajaj.*\\.?\\s?|jsjsj.*\\.?\\s?|j{1,}a{1,}s{1,}?j{1,}a{1,}s{1,}?.*\\.?\\s?", ":risa: "))

```



