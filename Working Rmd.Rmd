---
title: "Working Rmd"
author: '100385774'
date: "2023-04-18"
output: html_document
---

# 0. LOADING THE DATA

Data has been previously compiled into a single .csv document in the 'Preliminar.Rmd' file. 

```{r}
library(tidyverse)
library(ggplot2)
library(stringr)
library(openxlsx)
library(lubridate)
library(emo)
```


```{r}
df <- read.csv("data/tweets.csv")
```

# 1. MANUAL ANNOTATION

Duplicates removal, Spanish filtering: 

```{r}
df <- df %>% 
  distinct() %>% 
  filter(lang == "es") 
```

## Manual annotations

Filtering search for hate terms + random sampling.   

```{r}
set.seed(123)

annotation_1 <- df %>% 
  filter(str_detect(df$text, "moro")) %>% 
   sample_n(500, replace = FALSE)

annotation_2 <- df %>% 
  filter(str_detect(df$text, "negro|mono")) %>% 
   sample_n(500, replace = FALSE)

annotation_3 <- df %>% 
  filter(str_detect(df$text, "chino|sudaca|panchito|gitano")) %>% 
   sample_n(500, replace = FALSE)

annotation_4 <- df %>% 
  filter(str_detect(df$text, "maricon|maricÃ³n|travelo|transexual|travesti")) %>% 
   sample_n(500, replace = FALSE)

annotation_5 <- df %>% 
  filter(str_detect(df$text, "a tu pais|a tu paÃ­s|a su pais|a su paÃ­s")) %>% 
   sample_n(500, replace = FALSE)

annotation_6 <- df %>% 
  filter(str_detect(df$text, "puta|zorra|a la cocina|chupapollas")) %>% 
   sample_n(500, replace = FALSE)

annotation_random <- df %>% 
             sample_n(2000, replace = FALSE)
```

```{r}

annotation <- bind_rows(annotation_1, annotation_2, annotation_3, annotation_4, annotation_5, annotation_6, annotation_random) %>% 
  distinct() %>% 
  mutate(hate = 0) %>% 
  select(c(text, hate, id))

write.xlsx(annotation, file = "annotationbis.xlsx")

```

Loading the annotated tweets as training data: 

```{r}

annotation_a <- read.xlsx("data/annotationbis.xlsx")

annotation_b <- read.delim("data/HaterNet.txt", sep = ";", col.names = c("id", "X1", "text", "X2", "hate")) %>% 
  select(-c(X1, X2))

annotation_c <- read.delim("data/hateval/hateval2019_es_train.csv", sep = ",") %>% 
  select(-c(TR, AG)) %>% 
  rename(hate = HS) 

```

# 2. DATA PREPROCESSING: 

*APPLY LATER CLD3 PACKAGE

Noise removal (bots), Boolean mention and URL presence, lower casing, time conversion: 

```{r}
df <- df %>% 
  select(-c(lang, entities.hashtags)) %>% 
  distinct(text, author_id, .keep_all = TRUE) %>% 
  mutate(entities.mentions = ifelse(entities.mentions == "", F, T),
         entities.urls = ifelse(entities.urls == "", F, T),
         text = tolower(text), 
         created_at = as.POSIXct(created_at))
```

Emojis tokenization: 

```{r}
df <- df %>% 
  mutate(text = str_replace_all(text, "ðŸ»|ðŸ¼|ðŸ½|ðŸ¾|ðŸ¿", ""),
         text = str_replace_all(text, "\\\\n|&lt", " "), 
         text = str_replace_all(text, "ðŸ¤£+|ðŸ˜‚+", ":risa:"),
         text = str_replace_all(text, "ðŸ€+", ":rata:"),
         text = str_replace_all(text, "ðŸ˜¡+|ðŸ”ª+|ðŸ¤¬+|ðŸ‘Š+|ðŸª“+|ðŸ¤®+|ðŸ’©+", ":enfado:"),
         text = str_replace_all(text, "ðŸ‘+|ðŸ’ª+|âœŠ+|ðŸ’ª+|â¤ï¸+|ðŸ¥°+|â¤+|ðŸ¤+", ":positividad:"),
         text = ji_replace_all(text, ""),
         text = iconv(text, to = "UTF-8//IGNORE"))

```

Laughs tokenization: 

```{r}
df %>% 
  mutate(text = str_replace_all(text, "jajaja.*\\.?\\s?|jsjsjs.*\\.?\\s?|jajaj.*\\.?\\s?|jsjsj.*\\.?\\s?|j{1,}a{1,}s{1,}?j{1,}a{1,}s{1,}?.*\\.?\\s?", ":risa: "))
```


